{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94b65d9-909b-42c4-a3f3-eec0db1e4ef7",
   "metadata": {},
   "source": [
    "# 3️ Notebook 03 – Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daef6dd6-59ac-4193-90d4-15fc7ad5aae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Chemins projet\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\othni\\Projects\\mvtec_ad\")\n",
    "DATA_CSV = PROJECT_ROOT / \"experiments\" / \"image_level_df.csv\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a17a49-3c22-43b0-8d44-7f3170e7310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path category  split  label  \\\n",
      "0  C:\\Users\\othni\\Projects\\mvtec_ad\\data\\bottle\\t...   bottle  train      0   \n",
      "1  C:\\Users\\othni\\Projects\\mvtec_ad\\data\\bottle\\t...   bottle  train      0   \n",
      "2  C:\\Users\\othni\\Projects\\mvtec_ad\\data\\bottle\\t...   bottle  train      0   \n",
      "3  C:\\Users\\othni\\Projects\\mvtec_ad\\data\\bottle\\t...   bottle  train      0   \n",
      "4  C:\\Users\\othni\\Projects\\mvtec_ad\\data\\bottle\\t...   bottle  train      0   \n",
      "\n",
      "  defect_type final_split  \n",
      "0        good       train  \n",
      "1        good       train  \n",
      "2        good       train  \n",
      "3        good       train  \n",
      "4        good       train  \n",
      "\n",
      "final_split counts :\n",
      "final_split\n",
      "train    3629\n",
      "test      869\n",
      "val       856\n",
      "Name: count, dtype: int64\n",
      "\n",
      "label counts (global) :\n",
      "label\n",
      "0    4096\n",
      "1    1258\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "print(df.head())\n",
    "print(\"\\nfinal_split counts :\")\n",
    "print(df[\"final_split\"].value_counts())\n",
    "print(\"\\nlabel counts (global) :\")\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669d284b-f664-4dfe-b63d-d4e78a52e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecImageLevelDataset(Dataset):\n",
    "    def __init__(self, df_split, transform=None):\n",
    "        self.df = df_split.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = Path(row[\"path\"])\n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad9ae3-b192-4a83-9bf6-07bf017b9078",
   "metadata": {},
   "source": [
    "# Transforms & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f26721e-c38f-48f6-a6c6-c7a65f5dbd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille train : 3747\n",
      "Taille val   : 803\n",
      "Taille test  : 804\n",
      "\n",
      "Répartition des labels :\n",
      "Train:\n",
      " label\n",
      "0    2867\n",
      "1     880\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Val:\n",
      " label\n",
      "0    614\n",
      "1    189\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test:\n",
      " label\n",
      "0    615\n",
      "1    189\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Transforms type ImageNet\n",
    "# -----------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# --------------------------------------\n",
    "# 2) Re-split global pour le classifieur\n",
    "#    (avec des 0 et des 1 dans chaque split)\n",
    "# --------------------------------------\n",
    "df_all = df.copy()\n",
    "\n",
    "# 70% train, 15% val, 15% test, stratifié sur le label\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_all,\n",
    "    test_size=0.30,          # 30% pour val+test\n",
    "    random_state=42,\n",
    "    stratify=df_all[\"label\"]\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.50,          # moitié-moitié -> 15% / 15%\n",
    "    random_state=42,\n",
    "    stratify=temp_df[\"label\"]\n",
    ")\n",
    "\n",
    "df_train = train_df.reset_index(drop=True)\n",
    "df_val   = val_df.reset_index(drop=True)\n",
    "df_test  = test_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Taille train :\", len(df_train))\n",
    "print(\"Taille val   :\", len(df_val))\n",
    "print(\"Taille test  :\", len(df_test))\n",
    "\n",
    "print(\"\\nRépartition des labels :\")\n",
    "print(\"Train:\\n\", df_train[\"label\"].value_counts())\n",
    "print(\"\\nVal:\\n\", df_val[\"label\"].value_counts())\n",
    "print(\"\\nTest:\\n\", df_test[\"label\"].value_counts())\n",
    "\n",
    "# --------------------------------------\n",
    "# 3) Datasets & DataLoaders\n",
    "# --------------------------------------\n",
    "train_ds = MVTecImageLevelDataset(df_train, transform=train_transform)\n",
    "val_ds   = MVTecImageLevelDataset(df_val,   transform=eval_transform)\n",
    "test_ds  = MVTecImageLevelDataset(df_test,  transform=eval_transform)\n",
    "\n",
    "BATCH_SIZE = 32  # à ajuster si besoin\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4458f3e-1dc9-4205-a6a5-8efcc2bd48aa",
   "metadata": {},
   "source": [
    "# 4️ Définir le modèle ResNet binaire\n",
    "\n",
    "## Modèle + loss pondérée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "936ed2f9-a617-47e4-862b-c86193382ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Modèle ResNet-18 pré-entraîné ImageNet\n",
    "base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Remplacer la dernière couche (1000 classes) par 1 logit pour classification binaire\n",
    "in_features = base_model.fc.in_features\n",
    "base_model.fc = nn.Linear(in_features, 1)\n",
    "\n",
    "model = base_model.to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c5551a-9cdf-46b8-b21d-ebe0cf5197e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de normaux (0) : 2867\n",
      "Nombre de défauts (1) : 880\n",
      "pos_weight = 3.2579545454545453\n"
     ]
    }
   ],
   "source": [
    "# Calcul du poids de la classe positive (défauts) pour gérer le déséquilibre\n",
    "n_pos = (df_train[\"label\"] == 1).sum()\n",
    "n_neg = (df_train[\"label\"] == 0).sum()\n",
    "pos_weight_value = n_neg / n_pos\n",
    "pos_weight = torch.tensor([pos_weight_value], dtype=torch.float32, device=device)\n",
    "\n",
    "print(\"Nombre de normaux (0) :\", n_neg)\n",
    "print(\"Nombre de défauts (1) :\", n_pos)\n",
    "print(\"pos_weight =\", pos_weight_value)\n",
    "\n",
    "# Loss binaire avec logit + poids sur la classe positive\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Optimiseur\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Nombre d'époques (tu pourras augmenter ensuite)\n",
    "NUM_EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e58bcb1-f82d-490d-9b9e-22549c1d9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, optimizer=None):\n",
    "    \"\"\"\n",
    "    Si optimizer est None -> mode évaluation (pas de backprop).\n",
    "    Retourne : loss_moyenne, y_true (numpy), y_scores (numpy, logits).\n",
    "    \"\"\"\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    all_losses = []\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)  # (B,)\n",
    "\n",
    "        logits = model(imgs).squeeze(1)  # (B,)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        all_losses.append(loss.item())\n",
    "        all_labels.append(labels.detach().cpu().numpy())\n",
    "        all_scores.append(logits.detach().cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_scores = np.concatenate(all_scores)\n",
    "\n",
    "    avg_loss = float(np.mean(all_losses))\n",
    "    return avg_loss, all_labels, all_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2639faf0-e286-4c10-918a-ceca00583eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "  Train loss: 0.8105 | AUC: 0.8092\n",
      "  Val   loss: 0.7550 | AUC: 0.8664\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n",
      "\n",
      "Epoch 2/10\n",
      "  Train loss: 0.5823 | AUC: 0.9089\n",
      "  Val   loss: 0.5143 | AUC: 0.9310\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n",
      "\n",
      "Epoch 3/10\n",
      "  Train loss: 0.5039 | AUC: 0.9348\n",
      "  Val   loss: 0.4566 | AUC: 0.9425\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n",
      "\n",
      "Epoch 4/10\n",
      "  Train loss: 0.3759 | AUC: 0.9631\n",
      "  Val   loss: 0.4789 | AUC: 0.9489\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n",
      "\n",
      "Epoch 5/10\n",
      "  Train loss: 0.3777 | AUC: 0.9625\n",
      "  Val   loss: 0.3942 | AUC: 0.9617\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n",
      "\n",
      "Epoch 6/10\n",
      "  Train loss: 0.3115 | AUC: 0.9761\n",
      "  Val   loss: 0.4833 | AUC: 0.9586\n",
      "\n",
      "Epoch 7/10\n",
      "  Train loss: 0.2594 | AUC: 0.9833\n",
      "  Val   loss: 0.3457 | AUC: 0.9688\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n",
      "\n",
      "Epoch 8/10\n",
      "  Train loss: 0.2160 | AUC: 0.9881\n",
      "  Val   loss: 0.3116 | AUC: 0.9779\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n",
      "\n",
      "Epoch 9/10\n",
      "  Train loss: 0.2238 | AUC: 0.9868\n",
      "  Val   loss: 0.3085 | AUC: 0.9818\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n",
      "\n",
      "Epoch 10/10\n",
      "  Train loss: 0.2134 | AUC: 0.9902\n",
      "  Val   loss: 0.3179 | AUC: 0.9846\n",
      "  -> Nouveau meilleur modèle sauvegardé: C:\\Users\\othni\\Projects\\mvtec_ad\\models\\resnet18_image_level_best.pt\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = 0.0\n",
    "best_model_path = MODELS_DIR / \"resnet18_image_level_best.pt\"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    # --- Train ---\n",
    "    train_loss, train_y, train_scores = run_epoch(model, train_loader, optimizer=optimizer)\n",
    "    train_probs = torch.sigmoid(torch.tensor(train_scores)).numpy()\n",
    "    train_auc = roc_auc_score(train_y, train_probs)\n",
    "\n",
    "    # --- Validation ---\n",
    "    val_loss, val_y, val_scores = run_epoch(model, val_loader, optimizer=None)\n",
    "    val_probs = torch.sigmoid(torch.tensor(val_scores)).numpy()\n",
    "    val_auc = roc_auc_score(val_y, val_probs)\n",
    "\n",
    "    print(f\"  Train loss: {train_loss:.4f} | AUC: {train_auc:.4f}\")\n",
    "    print(f\"  Val   loss: {val_loss:.4f} | AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # Sauvegarde du meilleur modèle (selon AUC val)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"  -> Nouveau meilleur modèle sauvegardé: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5cf148a-de94-4488-8773-af814834070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3293 | Test AUC: 0.9793\n",
      "Nombre d'images test : 804\n"
     ]
    }
   ],
   "source": [
    "# Recréer un modèle ResNet-18 avec la même architecture\n",
    "best_model = models.resnet18(weights=None)\n",
    "in_features = best_model.fc.in_features\n",
    "best_model.fc = nn.Linear(in_features, 1)\n",
    "\n",
    "# Charger les poids sauvegardés\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "# Évaluation sur le test\n",
    "test_loss, test_y, test_scores = run_epoch(best_model, test_loader, optimizer=None)\n",
    "test_probs = torch.sigmoid(torch.tensor(test_scores)).numpy()\n",
    "test_auc = roc_auc_score(test_y, test_probs)\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4f} | Test AUC: {test_auc:.4f}\")\n",
    "print(\"Nombre d'images test :\", len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be2461cc-1f82-4987-aa56-64ee55a8f11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/othni/Projects/mvtec_ad/experiments/image_level_train_split.csv'),\n",
       " WindowsPath('C:/Users/othni/Projects/mvtec_ad/experiments/image_level_val_split.csv'),\n",
       " WindowsPath('C:/Users/othni/Projects/mvtec_ad/experiments/image_level_test_split.csv'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "splits_dir = PROJECT_ROOT / \"experiments\"\n",
    "splits_dir.mkdir(exist_ok=True)\n",
    "\n",
    "train_csv_path = splits_dir / \"image_level_train_split.csv\"\n",
    "val_csv_path   = splits_dir / \"image_level_val_split.csv\"\n",
    "test_csv_path  = splits_dir / \"image_level_test_split.csv\"\n",
    "\n",
    "df_train.to_csv(train_csv_path, index=False)\n",
    "df_val.to_csv(val_csv_path, index=False)\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "\n",
    "train_csv_path, val_csv_path, test_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4493a6-677e-44c8-9195-dfbec6c28ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
